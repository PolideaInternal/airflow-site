:mod:`airflow.operators.local_to_gcs`
=====================================

.. py:module:: airflow.operators.local_to_gcs

.. autoapi-nested-parse::

   This module contains operator for uploading local file to GCS.



Module Contents
---------------

.. py:class:: FileToGoogleCloudStorageOperator(src, dst, bucket, gcp_conn_id='google_cloud_default', google_cloud_storage_conn_id=None, mime_type='application/octet-stream', delegate_to=None, gzip=False, *args, **kwargs)

   Bases: :class:`airflow.models.BaseOperator`

   Uploads a file to Google Cloud Storage.
   Optionally can compress the file for upload.

   :param src: Path to the local file. (templated)
   :type src: str
   :param dst: Destination path within the specified bucket, it must be the full file path
       to destination object on GCS, including GCS object (ex. `path/to/file.txt`) (templated)
   :type dst: str
   :param bucket: The bucket to upload to. (templated)
   :type bucket: str
   :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud Platform.
   :type gcp_conn_id: str
   :param google_cloud_storage_conn_id: (Deprecated) The connection ID used to connect to Google Cloud
       Platform. This parameter has been deprecated. You should pass the gcp_conn_id parameter instead.
   :type google_cloud_storage_conn_id: str
   :param mime_type: The mime-type string
   :type mime_type: str
   :param delegate_to: The account to impersonate, if any
   :type delegate_to: str
   :param gzip: Allows for file to be compressed and uploaded as gzip
   :type gzip: bool

   .. attribute:: template_fields
      :annotation: = ['src', 'dst', 'bucket']

      

   
   .. method:: execute(self, context)

      Uploads the file to Google cloud storage




